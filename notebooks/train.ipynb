{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import logging\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import (Dataset, DataLoader)\n",
    "\n",
    "from ctorch.config import ComplexTorchConfig\n",
    "from ctorch.data_access import DataClass\n",
    "from ctorch.model import UNetModel\n",
    "from ctorch.utils import kspace, fft\n",
    "from ctorch.utils.constants import (\n",
    "    PROCESSED_DIR,\n",
    "    TRAIN,\n",
    "    VAL,\n",
    "    TEST,\n",
    "    INPUT,\n",
    "    TARGET,\n",
    "    HEIGHT,\n",
    "    WIDTH,\n",
    "    SAVED_MODELS_DIR\n",
    ")\n",
    "\n",
    "PARENT_PATH = Path(os.getcwd()).parent.absolute()\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "FORMAT = \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)\n",
    "\n",
    "# seed everything\n",
    "seed = 128\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ComplexTorchConfig()\n",
    "config.CURRENT_PATH = PARENT_PATH\n",
    "\n",
    "data = DataClass(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KSpaceDataset(Dataset):\n",
    "    def __init__(self, input_path: Path, target_path: Path):\n",
    "        super().__init__()\n",
    "        self.input_path = input_path\n",
    "        self.target_path = target_path\n",
    "        self.files = sorted(os.listdir(self.input_path))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = self.files[idx]\n",
    "        X = np.load(os.path.join(self.input_path, file))\n",
    "        Y = np.load(os.path.join(self.target_path, file))\n",
    "        X = torch.from_numpy(X)\n",
    "        Y = torch.from_numpy(Y)\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_loader(\n",
    "    input_path: Path,\n",
    "    target_path: Path,\n",
    "    batch_size: int,\n",
    "    shuffle: bool = True,\n",
    "    num_workers: int = 0\n",
    "    ) -> DataLoader:\n",
    "    data = KSpaceDataset(input_path=input_path, target_path=target_path)\n",
    "    data_loader = DataLoader(\n",
    "        dataset=data,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = max(0, multiprocessing.cpu_count() - 2)\n",
    "\n",
    "train_input_path = os.path.join(data.data_path, PROCESSED_DIR, TRAIN, INPUT)\n",
    "train_target_path = os.path.join(data.data_path, PROCESSED_DIR, TRAIN, TARGET)\n",
    "train_loader = make_data_loader(\n",
    "    input_path=train_input_path,\n",
    "    target_path=train_target_path,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "valid_input_path = os.path.join(data.data_path, PROCESSED_DIR, VAL, INPUT)\n",
    "valid_target_path = os.path.join(data.data_path, PROCESSED_DIR, VAL, TARGET)\n",
    "valid_loader = make_data_loader(\n",
    "    input_path=valid_input_path,\n",
    "    target_path=valid_target_path,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "print(f\"Number of training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Number of validation samples: {len(valid_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with batch size of 16 for 200 epochs\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "LEARNING_RATE = 1e-03\n",
    "FACTOR = 0.1\n",
    "PATIENCE = 2\n",
    "VERBOSE = True\n",
    "\n",
    "model = UNetModel(config)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    factor=FACTOR,\n",
    "    patience=PATIENCE,\n",
    "    verbose=VERBOSE\n",
    ")\n",
    "\n",
    "saved_models_path = Path(os.path.join(data.current_path, SAVED_MODELS_DIR))\n",
    "saved_models_path.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Training with batch size of {BATCH_SIZE} for {EPOCHS} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " EPOCH:1/200, step:12/441, loss=0.0007412802078761166"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     23\u001b[0m \u001b[39m# Backward pass (backpropogation)\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     25\u001b[0m \u001b[39m# Update weights\u001b[39;00m\n\u001b[1;32m     26\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/ctorch/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ctorch/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Move model to device\n",
    "model.to(device)\n",
    "# Lists to keep the losses and evaluation scores at the end of each epoch\n",
    "train_loss, valid_loss = list(), list()\n",
    "# train_eval, valid_eval = list(), list()\n",
    "for epoch in range(EPOCHS):\n",
    "    # Dummy lists to keep the losses and evaluation scores at the end of each iteration\n",
    "    # (one batch forward and backward process)\n",
    "    train_batch_loss, valid_batch_loss = list(), list()\n",
    "    train_batch_eval, valid_batch_eval = list(), list()\n",
    "    # Training mode\n",
    "    model.train()\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        # Move input to device\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # Forward pass\n",
    "        residual = model(x)\n",
    "        # Calculate loss\n",
    "        loss = criterion(torch.view_as_real(residual), torch.view_as_real(y - x))\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Backward pass (backpropogation)\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        # Collect loss and evaluation scores\n",
    "        train_batch_loss.append(loss.item())\n",
    "        # train_batch_eval.append(eval(residual + x, y))\n",
    "        message = \\\n",
    "            f\"EPOCH:{epoch+1}/{EPOCHS}, \" + \\\n",
    "            f\"step:{i+1}/{len(train_loader)}, \" + \\\n",
    "            f\"loss={loss.item()}\"\n",
    "        print(\"\\r\", message, end=\"\")\n",
    "    # Take the average of iteration losses and evaluation scores\n",
    "    # and append to respective lists\n",
    "    train_loss.append(np.array(train_batch_loss).mean())\n",
    "    # train_eval.append(np.array(train_batch_eval).mean(axis=0))\n",
    "    # Evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(valid_loader):\n",
    "            # Move input to device\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            # Forward pass\n",
    "            residual = model(x)\n",
    "            # Calculate loss\n",
    "            loss = criterion(torch.view_as_real(residual), torch.view_as_real(y - x))\n",
    "            valid_batch_loss.append(loss.item())\n",
    "            # valid_batch_eval.append(eval(residual+x, y))\n",
    "            message = \\\n",
    "                f\"EPOCH:{epoch+1}/{self.epochs}, \" + \\\n",
    "                f\"step:{i+1}/{len(valid_loader)}, \" + \\\n",
    "                f\"loss={loss.item()}\"\n",
    "            print(\"\\r\", message, end=\"\")\n",
    "    # Take the average of iteration losses and evaluation scores\n",
    "    # and append to respective lists\n",
    "    valid_loss.append(np.array(valid_batch_loss).mean())\n",
    "    scheduler.step(valid_loss[-1])\n",
    "    # valid_eval.append(np.array(valid_batch_eval).mean(axis=0))\n",
    "    message = \\\n",
    "        f\"EPOCH:{epoch+1}/{EPOCHS} - \" + \\\n",
    "        f\"Training Loss: {train_loss[-1]}, \" + \\\n",
    "        f\"Validation Loss: {valid_loss[-1]}\"\n",
    "    print(\"\\r\", message)\n",
    "    # Save model\n",
    "    state = f\"epoch_{epoch+1:03}.pth\"\n",
    "    state_dict_path = os.path.join(saved_models_path, state)\n",
    "    torch.save(model.state_dict(), state_dict_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = np.argmin(valid_loss) + 1\n",
    "print(f\"Best epoch: {best_epoch}\")\n",
    "state = f\"epoch_{best_epoch:03}.pth\"\n",
    "state_dict_path = os.path.join(saved_models_path, state)\n",
    "state_dict = torch.load(state_dict_path)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
